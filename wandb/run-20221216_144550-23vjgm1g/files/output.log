loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
loading annotations into memory...
Done (t=0.00s)
creating index...
index created!
Number of training examples: 61
Number of validation examples: 13
Some weights of DeformableDetrForObjectDetection were not initialized from the model checkpoint at SenseTime/deformable-detr and are newly initialized because the shapes did not match:
- class_embed.0.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.0.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
- class_embed.1.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.1.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
- class_embed.2.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.2.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
- class_embed.3.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.3.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
- class_embed.4.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.4.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
- class_embed.5.weight: found shape torch.Size([91, 256]) in the checkpoint and torch.Size([1, 256]) in the model instantiated
- class_embed.5.bias: found shape torch.Size([91]) in the checkpoint and torch.Size([1]) in the model instantiated
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
CUDA_VISIBLE_DEVICES: [0]
/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: RuntimeWarning: You have defined a `val_dataloader()` and have defined a `validation_step()`, you may also want to define `validation_epoch_end()` for accumulating stats.
  warnings.warn(*args, **kwargs)
  | Name  | Type                             | Params
-----------------------------------------------------------
0 | model | DeformableDetrForObjectDetection | 40 M
/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
Validation sanity check: 0it [00:00, ?it/s]
/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541035/work/aten/src/ATen/native/TensorShape.cpp:3190.)


Epoch 1:   0%|                                                                                                                                                                                                                   | 0/35 [00:00<?, ?it/s]
/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  warnings.warn(*args, **kwargs)
Traceback (most recent call last):
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 670, in forward
    self.im2col_step,
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 74, in forward
    output = MultiScaleDeformableAttention.ms_deform_attn_forward(
AttributeError: 'NoneType' object has no attribute 'ms_deform_attn_forward'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py", line 39, in <module>
    cli.main()
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 430, in main
    run()
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py", line 284, in run_file
    runpy.run_path(target, run_name="__main__")
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 322, in run_path
    pkg_name=pkg_name, script_name=fname)
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 136, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File "/home/userfs/j/jrs596/.vscode-server/extensions/ms-python.python-2022.20.1/pythonFiles/lib/python/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
    exec(code, run_globals)
  File "/home/userfs/j/jrs596/scripts/Elodea/fine_tune_d-detr2.py", line 173, in <module>
    main()
  File "/home/userfs/j/jrs596/scripts/Elodea/fine_tune_d-detr2.py", line 125, in main
    trainer.fit(model)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1003, in fit
    results = self.single_gpu_train(model)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/distrib_parts.py", line 186, in single_gpu_train
    results = self.run_pretrain_routine(model)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1213, in run_pretrain_routine
    self.train()
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 370, in train
    self.run_training_epoch()
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 452, in run_training_epoch
    batch_output = self.run_training_batch(batch, batch_idx)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 632, in run_training_batch
    self.hiddens
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 776, in optimizer_closure
    hiddens)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/pytorch_lightning/trainer/training_loop.py", line 946, in training_forward
    output = self.model.training_step(*args)
  File "/home/userfs/j/jrs596/scripts/Elodea/fine_tune_d-detr2.py", line 72, in training_step
    loss, loss_dict = self.common_step(batch, batch_idx)
  File "/home/userfs/j/jrs596/scripts/Elodea/fine_tune_d-detr2.py", line 65, in common_step
    outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 1906, in forward
    return_dict=return_dict,
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 1701, in forward
    return_dict=return_dict,
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 1217, in forward
    output_attentions=output_attentions,
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 855, in forward
    output_attentions=output_attentions,
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 674, in forward
    output = ms_deform_attn_core_pytorch(value, spatial_shapes, sampling_locations, attention_weights)
  File "/scratch/staff/jrs596/python_environments/envs/def_detr_pl/lib/python3.7/site-packages/transformers/models/deformable_detr/modeling_deformable_detr.py", line 550, in ms_deform_attn_core_pytorch
    output = (torch.stack(sampling_value_list, dim=-2).flatten(-2) * attention_weights).sum(-1).view(N_, M_ * D_, Lq_)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 836.00 MiB (GPU 0; 10.92 GiB total capacity; 9.06 GiB already allocated; 525.56 MiB free; 9.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF